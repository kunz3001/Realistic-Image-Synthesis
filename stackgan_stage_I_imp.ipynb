{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrrajatgarg/StackGAN/blob/master/stackgan_stage_I_imp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fBRj1Lxsle4H"
   },
   "source": [
    "# Stage I GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "psC9UHjzliA1"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ml58N7F-jnLh",
    "outputId": "e2dd3ad8-ccd0-4c1d-bee9-bf5ab682881a"
   },
   "outputs": [],
   "source": [
    "#%tensorflow version 1.x\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\n",
    "    concatenate, Flatten, Lambda, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZybHodapH3H"
   },
   "source": [
    "# Loading of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMvLOjXalnKd"
   },
   "outputs": [],
   "source": [
    "def load_class_ids(class_info_file_path):\n",
    "    \"\"\"\n",
    "    Load class ids from class_info.pickle file\n",
    "    \"\"\"\n",
    "    with open(class_info_file_path, 'rb') as f:\n",
    "        class_ids = pickle.load(f, encoding='latin1')\n",
    "        return class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifdCVSGco5pD"
   },
   "outputs": [],
   "source": [
    "def load_embeddings(embeddings_file_path):\n",
    "    \"\"\"\n",
    "    Load embeddings\n",
    "    \"\"\"\n",
    "    with open(embeddings_file_path, 'rb') as f:\n",
    "        embeddings = pickle.load(f, encoding='latin1')\n",
    "        embeddings = np.array(embeddings)\n",
    "        print('embeddings: ', embeddings.shape)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fkwKbQgvo7pG"
   },
   "outputs": [],
   "source": [
    "def load_filenames(filenames_file_path):\n",
    "    \"\"\"\n",
    "    Load filenames.pickle file and return a list of all file names\n",
    "    \"\"\"\n",
    "    with open(filenames_file_path, 'rb') as f:\n",
    "        filenames = pickle.load(f, encoding='latin1')\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxlUAsjuo-i5"
   },
   "outputs": [],
   "source": [
    "def load_bounding_boxes(dataset_dir):\n",
    "    \"\"\"\n",
    "    Load bounding boxes and return a dictionary of file names and corresponding bounding boxes\n",
    "    \"\"\"\n",
    "    # Paths\n",
    "    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n",
    "    file_paths_path = os.path.join(dataset_dir, 'images.txt')\n",
    "\n",
    "    # Read bounding_boxes.txt and images.txt file\n",
    "    df_bounding_boxes = pd.read_csv(bounding_boxes_path,\n",
    "                                    delim_whitespace=True, header=None).astype(int)\n",
    "    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n",
    "\n",
    "    # Create a list of file names\n",
    "    file_names = df_file_names[1].tolist()\n",
    "\n",
    "    # Create a dictionary of file_names and bounding boxes\n",
    "    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n",
    "\n",
    "    # Assign a bounding box to the corresponding image\n",
    "    for i in range(0, len(file_names)):\n",
    "        # Get the bounding box\n",
    "        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n",
    "        key = file_names[i][:-4]\n",
    "        filename_boundingbox_dict[key] = bounding_box\n",
    "\n",
    "    return filename_boundingbox_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQf-MsWtpAyk"
   },
   "outputs": [],
   "source": [
    "def get_img(img_path, bbox, image_size):\n",
    "    \"\"\"\n",
    "    Load and resize image\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    if bbox is not None:\n",
    "        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
    "        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
    "        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
    "        y1 = np.maximum(0, center_y - R)\n",
    "        y2 = np.minimum(height, center_y + R)\n",
    "        x1 = np.maximum(0, center_x - R)\n",
    "        x2 = np.minimum(width, center_x + R)\n",
    "        img = img.crop([x1, y1, x2, y2])\n",
    "    img = img.resize(image_size, PIL.Image.BILINEAR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gk-4oF83Su2v"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEtbSBB8pCfo"
   },
   "outputs": [],
   "source": [
    "def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):\n",
    "    \"\"\"\n",
    "    Load dataset\n",
    "    \"\"\"\n",
    "    filenames = load_filenames(filenames_file_path)\n",
    "    class_ids = load_class_ids(class_info_file_path)\n",
    "    bounding_boxes = load_bounding_boxes(cub_dataset_dir)\n",
    "    all_embeddings = load_embeddings(embeddings_file_path)\n",
    "\n",
    "    X, y, embeddings = [], [], []\n",
    "\n",
    "    print(\"Embeddings shape:\", all_embeddings.shape)\n",
    "\n",
    "    for index, filename in enumerate(filenames):\n",
    "        bounding_box = bounding_boxes[filename]\n",
    "\n",
    "        try:\n",
    "            # Load images\n",
    "            img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\n",
    "            img = get_img(img_name, bounding_box, image_size)\n",
    "\n",
    "            all_embeddings1 = all_embeddings[index, :, :]\n",
    "\n",
    "            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n",
    "            embedding = all_embeddings1[embedding_ix, :]\n",
    "\n",
    "            X.append(np.array(img))\n",
    "            y.append(class_ids[index])\n",
    "            embeddings.append(embedding)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    embeddings = np.array(embeddings)\n",
    "    return X, y, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODvYdkGtpGKJ"
   },
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__1ejH3mpFon"
   },
   "outputs": [],
   "source": [
    "def generate_c(x):\n",
    "    mean = x[:, :128]\n",
    "    log_sigma = x[:, 128:]\n",
    "    stddev = K.exp(log_sigma)\n",
    "    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))\n",
    "    c = stddev * epsilon + mean\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LYGM28snpPMb"
   },
   "outputs": [],
   "source": [
    "def build_ca_model():\n",
    "    \"\"\"\n",
    "    Get conditioning augmentation model.\n",
    "    Takes an embedding of shape (1024,) and returns a tensor of shape (256,)\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    x = Dense(256)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    model = Model(inputs=[input_layer], outputs=[x])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jY_cMcEbpRSW"
   },
   "outputs": [],
   "source": [
    "def build_embedding_compressor_model():\n",
    "    \"\"\"\n",
    "    Build embedding compressor model\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    x = Dense(128)(input_layer)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=[x])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5BK6rWkpSyQ"
   },
   "outputs": [],
   "source": [
    "def build_stage1_generator():\n",
    "    \"\"\"\n",
    "    Builds a generator model used in Stage-I\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    x = Dense(256)(input_layer)\n",
    "    mean_logsigma = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    c = Lambda(generate_c)(mean_logsigma)\n",
    "\n",
    "    input_layer2 = Input(shape=(100,))\n",
    "\n",
    "    gen_input = Concatenate(axis=1)([c, input_layer2])\n",
    "\n",
    "    x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = Activation(activation='tanh')(x)\n",
    "\n",
    "    stage1_gen = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma])\n",
    "    return stage1_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xJLclqSTpVGj"
   },
   "outputs": [],
   "source": [
    "def build_stage1_discriminator():\n",
    "    \"\"\"\n",
    "    Create a model which takes two inputs\n",
    "    1. One from above network\n",
    "    2. One from the embedding layer\n",
    "    3. Concatenate along the axis dimension and feed it to the last module which produces final logits\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(64, 64, 3))\n",
    "\n",
    "    x = Conv2D(64, (4, 4),\n",
    "               padding='same', strides=2,\n",
    "               input_shape=(64, 64, 3), use_bias=False)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    input_layer2 = Input(shape=(4, 4, 128))\n",
    "\n",
    "    merged_input = concatenate([x, input_layer2])\n",
    "\n",
    "    x2 = Conv2D(64 * 8, kernel_size=1,\n",
    "                padding=\"same\", strides=1)(merged_input)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.2)(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = Dense(1)(x2)\n",
    "    x2 = Activation('sigmoid')(x2)\n",
    "\n",
    "    stage1_dis = Model(inputs=[input_layer, input_layer2], outputs=[x2])\n",
    "    return stage1_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NREfScoDpXKb"
   },
   "outputs": [],
   "source": [
    "def build_adversarial_model(gen_model, dis_model):\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    input_layer2 = Input(shape=(100,))\n",
    "    input_layer3 = Input(shape=(4, 4, 128))\n",
    "\n",
    "    x, mean_logsigma = gen_model([input_layer, input_layer2])\n",
    "\n",
    "    dis_model.trainable = False\n",
    "    valid = dis_model([x, input_layer3])\n",
    "\n",
    "    model = Model(inputs=[input_layer, input_layer2, input_layer3], outputs=[valid, mean_logsigma])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eNBHRmpqpZgo"
   },
   "source": [
    "# Defining Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "awQ2XK6lpZDr"
   },
   "outputs": [],
   "source": [
    "def KL_loss(y_true, y_pred):\n",
    "    mean = y_pred[:, :128]\n",
    "    logsigma = y_pred[:, :128]\n",
    "    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n",
    "    loss = K.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6wkVR9lpd5q"
   },
   "outputs": [],
   "source": [
    "\n",
    "def custom_generator_loss(y_true, y_pred):\n",
    "    # Calculate binary cross entropy loss\n",
    "    return K.binary_crossentropy(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wGTNAxZpfoc"
   },
   "outputs": [],
   "source": [
    "def save_rgb_img(img, path):\n",
    "    \"\"\"\n",
    "    Save an rgb image\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Image\")\n",
    "\n",
    "    plt.savefig(path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfdGkJj0phPb"
   },
   "outputs": [],
   "source": [
    "def write_log(callback, name, loss, batch_no):\n",
    "    \"\"\"\n",
    "    Write training summary to TensorBoard\n",
    "    \"\"\"\n",
    "    #with self.writer.as_default():\n",
    "     #   tf.summary.scalar(name,loss)\n",
    "      #  self.writer=tf.summary.create_file_writer(log_dir)\n",
    "       # self.writer.flush()\n",
    "    summary=tf.Summary()\n",
    "    summary_value = summary.value.add()\n",
    "    summary_value.simple_value = loss\n",
    "    summary_value.tag = name\n",
    "    callback.writer.add_summary(summary, batch_no)\n",
    "    callback.writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTgvkqyvptfn"
   },
   "source": [
    "# Downloading of dataset in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "HFIC465b2w0u",
    "outputId": "030d80eb-24f4-4742-f068-b3f75b9ef7f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rdxKQ0663T_C",
    "outputId": "886fbb23-0435-4b08-cbe4-5801e0afcdf0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHohaW6L2wyW"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CUB_200_2011.tgz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-73f17adcf092>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CUB_200_2011.tgz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[0;32m   1571\u001b[0m                     \u001b[0msaved_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1573\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1574\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mReadError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1575\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[1;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"b\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1639\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CUB_200_2011.tgz'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "jZ6Xgi--2wvp",
    "outputId": "59f7ebfe-40cf-4cfe-f8ff-62a0cc3bd303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adc.json\tbirds.zip  cub\t\t     cub.tar.gz  results\n",
      "attributes.txt\tcoco\t   CUB_200_2011      logs\t sample_data\n",
      "birds\t\tcoco.zip   CUB_200_2011.tgz  __MACOSX\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0fTLsFUb4ftd",
    "outputId": "b8ce771b-a488-43ac-a587-dccfe98c3106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/CUB_200_2011\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "4_xbNKn-4f5r",
    "outputId": "0785899d-b37f-4342-d211-c7a6787d4cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributes\t    image_class_labels.txt  parts\n",
      "bounding_boxes.txt  images\t\t    README\n",
      "classes.txt\t    images.txt\t\t    train_test_split.txt\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdEAGWQE4gB-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9BMrVDAC4gMN",
    "outputId": "04657c0c-fb68-4c5e-c805-a1f1f1054845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adc.json\tbirds.zip  cub\t\t     cub.tar.gz  results\n",
      "attributes.txt\tcoco\t   CUB_200_2011      logs\t sample_data\n",
      "birds\t\tcoco.zip   CUB_200_2011.tgz  __MACOSX\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWRKO6IfpkFt"
   },
   "source": [
    "# Main File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Pjt8uWEpjsS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings:  (8855, 10, 1024)\n",
      "Embeddings shape: (8855, 10, 1024)\n",
      "embeddings:  (2933, 10, 1024)\n",
      "Embeddings shape: (2933, 10, 1024)\n",
      "[Errno 2] No such file or directory: './CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0088_796133.jpg'\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "========================================\n",
      "Epoch is: 0\n",
      "Number of batches 138\n",
      "Batch:1\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "d_loss_real:0.552016019821167\n",
      "d_loss_fake:4.68302059173584\n",
      "d_loss_wrong:5.190763473510742\n",
      "d_loss:2.744454026222229\n",
      "g_loss:[1.425044, 1.3810849, 0.021979494]\n",
      "Batch:2\n",
      "d_loss_real:1.4986051321029663\n",
      "d_loss_fake:0.17714829742908478\n",
      "d_loss_wrong:0.8648850321769714\n",
      "d_loss:1.009810894727707\n",
      "g_loss:[3.6462173, 3.599741, 0.023238238]\n",
      "Batch:3\n",
      "d_loss_real:2.5324392318725586\n",
      "d_loss_fake:1.487140417098999\n",
      "d_loss_wrong:1.018307089805603\n",
      "d_loss:1.8925814628601074\n",
      "g_loss:[4.913437, 4.8524456, 0.03049573]\n",
      "Batch:4\n",
      "d_loss_real:2.9533028602600098\n",
      "d_loss_fake:0.03161213919520378\n",
      "d_loss_wrong:2.2183775901794434\n",
      "d_loss:2.0391488671302795\n",
      "g_loss:[3.7566035, 3.7111702, 0.022716653]\n",
      "Batch:5\n",
      "d_loss_real:2.3012781143188477\n",
      "d_loss_fake:0.10419881343841553\n",
      "d_loss_wrong:2.0456695556640625\n",
      "d_loss:1.6881061792373657\n",
      "g_loss:[2.8312356, 2.7931285, 0.019053545]\n",
      "Batch:6\n",
      "d_loss_real:2.4349660873413086\n",
      "d_loss_fake:0.013281719759106636\n",
      "d_loss_wrong:1.8032300472259521\n",
      "d_loss:1.6716109812259674\n",
      "g_loss:[1.6999708, 1.6630994, 0.018435698]\n",
      "Batch:7\n",
      "d_loss_real:2.048861503601074\n",
      "d_loss_fake:0.3601260781288147\n",
      "d_loss_wrong:0.836288571357727\n",
      "d_loss:1.3235344290733337\n",
      "g_loss:[2.2304003, 2.1987114, 0.015844522]\n",
      "Batch:8\n",
      "d_loss_real:2.8018980026245117\n",
      "d_loss_fake:0.0008438530494458973\n",
      "d_loss_wrong:0.6275498867034912\n",
      "d_loss:1.5580474436283112\n",
      "g_loss:[0.7454138, 0.676703, 0.034355413]\n",
      "Batch:9\n",
      "d_loss_real:1.7599157094955444\n",
      "d_loss_fake:0.04088760167360306\n",
      "d_loss_wrong:1.5856943130493164\n",
      "d_loss:1.286603331565857\n",
      "g_loss:[0.67656934, 0.6085921, 0.033988625]\n",
      "Batch:10\n",
      "d_loss_real:1.2921268939971924\n",
      "d_loss_fake:0.0887795016169548\n",
      "d_loss_wrong:1.06448233127594\n",
      "d_loss:0.9343788921833038\n",
      "g_loss:[1.3056442, 1.2505232, 0.027560486]\n",
      "Batch:11\n",
      "d_loss_real:1.6704564094543457\n",
      "d_loss_fake:0.4416712522506714\n",
      "d_loss_wrong:0.6912893056869507\n",
      "d_loss:1.1184683442115784\n",
      "g_loss:[4.399893, 4.3553114, 0.022290712]\n",
      "Batch:12\n",
      "d_loss_real:2.0105764865875244\n",
      "d_loss_fake:0.04318401217460632\n",
      "d_loss_wrong:0.834494948387146\n",
      "d_loss:1.2247079908847809\n",
      "g_loss:[2.8854303, 2.843874, 0.020778127]\n",
      "Batch:13\n",
      "d_loss_real:1.6906591653823853\n",
      "d_loss_fake:0.1598028689622879\n",
      "d_loss_wrong:0.9081291556358337\n",
      "d_loss:1.1123125851154327\n",
      "g_loss:[3.298029, 3.2575529, 0.020238057]\n",
      "Batch:14\n",
      "d_loss_real:1.611215591430664\n",
      "d_loss_fake:0.01886076107621193\n",
      "d_loss_wrong:1.0250539779663086\n",
      "d_loss:1.0665864944458008\n",
      "g_loss:[2.3414454, 2.3098438, 0.015800783]\n",
      "Batch:15\n",
      "d_loss_real:1.1411466598510742\n",
      "d_loss_fake:0.05154430866241455\n",
      "d_loss_wrong:1.3490558862686157\n",
      "d_loss:0.9207233786582947\n",
      "g_loss:[3.2810135, 3.227364, 0.026824743]\n",
      "Batch:16\n",
      "d_loss_real:1.1740069389343262\n",
      "d_loss_fake:0.009406480006873608\n",
      "d_loss_wrong:1.0896371603012085\n",
      "d_loss:0.8617643713951111\n",
      "g_loss:[2.6472836, 2.591034, 0.028124833]\n",
      "Batch:17\n",
      "d_loss_real:1.3442914485931396\n",
      "d_loss_fake:0.0200121458619833\n",
      "d_loss_wrong:1.4453198909759521\n",
      "d_loss:1.0384787321090698\n",
      "g_loss:[0.9140618, 0.8700735, 0.021994136]\n",
      "Batch:18\n",
      "d_loss_real:1.371370792388916\n",
      "d_loss_fake:0.23257075250148773\n",
      "d_loss_wrong:0.6487889885902405\n",
      "d_loss:0.9060253351926804\n",
      "g_loss:[2.4946775, 2.4512691, 0.021704236]\n",
      "Batch:19\n",
      "d_loss_real:1.6015958786010742\n",
      "d_loss_fake:0.05236499011516571\n",
      "d_loss_wrong:0.8632433414459229\n",
      "d_loss:1.0297000259160995\n",
      "g_loss:[2.8718247, 2.8400464, 0.015889112]\n",
      "Batch:20\n",
      "d_loss_real:1.4711365699768066\n",
      "d_loss_fake:0.19307738542556763\n",
      "d_loss_wrong:0.8763630986213684\n",
      "d_loss:1.0029284060001373\n",
      "g_loss:[4.0405116, 4.0033493, 0.018581182]\n",
      "Batch:21\n",
      "d_loss_real:1.6132804155349731\n",
      "d_loss_fake:0.03870055824518204\n",
      "d_loss_wrong:0.6311227679252625\n",
      "d_loss:0.9740960448980331\n",
      "g_loss:[4.020009, 3.9803247, 0.019842219]\n",
      "Batch:22\n",
      "d_loss_real:1.2216278314590454\n",
      "d_loss_fake:0.021738654002547264\n",
      "d_loss_wrong:1.034848928451538\n",
      "d_loss:0.8749608099460602\n",
      "g_loss:[2.5035646, 2.4601738, 0.021695353]\n",
      "Batch:23\n",
      "d_loss_real:1.1641709804534912\n",
      "d_loss_fake:0.008395573124289513\n",
      "d_loss_wrong:0.8208523392677307\n",
      "d_loss:0.7893974632024765\n",
      "g_loss:[1.8517239, 1.8150806, 0.018321637]\n",
      "Batch:24\n",
      "d_loss_real:0.9760998487472534\n",
      "d_loss_fake:0.06642986088991165\n",
      "d_loss_wrong:0.8574095368385315\n",
      "d_loss:0.7190097719430923\n",
      "g_loss:[2.1099415, 2.064737, 0.022602204]\n",
      "Batch:25\n",
      "d_loss_real:1.2437570095062256\n",
      "d_loss_fake:0.006961272098124027\n",
      "d_loss_wrong:0.8915853500366211\n",
      "d_loss:0.8465151637792587\n",
      "g_loss:[1.9820862, 1.9287658, 0.026660226]\n",
      "Batch:26\n",
      "d_loss_real:1.0744543075561523\n",
      "d_loss_fake:0.008478650823235512\n",
      "d_loss_wrong:0.9029841423034668\n",
      "d_loss:0.7650928497314453\n",
      "g_loss:[1.327133, 1.2798724, 0.023630312]\n",
      "Batch:27\n",
      "d_loss_real:1.2246732711791992\n",
      "d_loss_fake:0.13678202033042908\n",
      "d_loss_wrong:0.9522284865379333\n",
      "d_loss:0.8845892548561096\n",
      "g_loss:[3.2650774, 3.22638, 0.0193486]\n",
      "Batch:28\n",
      "d_loss_real:1.1800495386123657\n",
      "d_loss_fake:0.0012111366959288716\n",
      "d_loss_wrong:0.8152559995651245\n",
      "d_loss:0.794141560792923\n",
      "g_loss:[2.7507706, 2.6794362, 0.03566715]\n",
      "Batch:29\n",
      "d_loss_real:1.1489131450653076\n",
      "d_loss_fake:0.017618834972381592\n",
      "d_loss_wrong:0.7650980353355408\n",
      "d_loss:0.7701357901096344\n",
      "g_loss:[2.9351172, 2.8814223, 0.026847474]\n",
      "Batch:30\n",
      "d_loss_real:1.1166491508483887\n",
      "d_loss_fake:0.12045606970787048\n",
      "d_loss_wrong:0.9821995496749878\n",
      "d_loss:0.8339884877204895\n",
      "g_loss:[4.0446005, 4.003604, 0.020498287]\n",
      "Batch:31\n",
      "d_loss_real:1.0781590938568115\n",
      "d_loss_fake:0.031005924567580223\n",
      "d_loss_wrong:0.7920588850975037\n",
      "d_loss:0.7448457479476929\n",
      "g_loss:[5.3619275, 5.3123183, 0.02480456]\n",
      "Batch:32\n",
      "d_loss_real:1.1758830547332764\n",
      "d_loss_fake:0.028025273233652115\n",
      "d_loss_wrong:0.6538687944412231\n",
      "d_loss:0.7584150433540344\n",
      "g_loss:[3.232002, 3.1768117, 0.02759517]\n",
      "Batch:33\n",
      "d_loss_real:1.0638060569763184\n",
      "d_loss_fake:0.06090738624334335\n",
      "d_loss_wrong:0.7779340744018555\n",
      "d_loss:0.7416133880615234\n",
      "g_loss:[3.0232406, 2.9744232, 0.024408717]\n",
      "Batch:34\n",
      "d_loss_real:1.1375598907470703\n",
      "d_loss_fake:0.05884063243865967\n",
      "d_loss_wrong:0.7045789361000061\n",
      "d_loss:0.7596348375082016\n",
      "g_loss:[2.322406, 2.269915, 0.026245432]\n",
      "Batch:35\n",
      "d_loss_real:1.0690733194351196\n",
      "d_loss_fake:0.054045360535383224\n",
      "d_loss_wrong:0.816861093044281\n",
      "d_loss:0.7522632777690887\n",
      "g_loss:[2.058759, 2.007964, 0.02539757]\n",
      "Batch:36\n",
      "d_loss_real:1.0630650520324707\n",
      "d_loss_fake:0.06088373437523842\n",
      "d_loss_wrong:0.7333462238311768\n",
      "d_loss:0.7300900220870972\n",
      "g_loss:[1.5386379, 1.4867573, 0.025940321]\n",
      "Batch:37\n",
      "d_loss_real:1.115431547164917\n",
      "d_loss_fake:0.17522898316383362\n",
      "d_loss_wrong:0.7249497771263123\n",
      "d_loss:0.7827604711055756\n",
      "g_loss:[1.4933393, 1.4380486, 0.027645327]\n",
      "Batch:38\n",
      "d_loss_real:1.1452192068099976\n",
      "d_loss_fake:0.272988498210907\n",
      "d_loss_wrong:0.6644592881202698\n",
      "d_loss:0.806971549987793\n",
      "g_loss:[2.0008695, 1.9401155, 0.030377056]\n",
      "Batch:39\n",
      "d_loss_real:1.2608928680419922\n",
      "d_loss_fake:0.10496648401021957\n",
      "d_loss_wrong:0.6426317691802979\n",
      "d_loss:0.81734599173069\n",
      "g_loss:[1.0814675, 1.0213051, 0.030081218]\n",
      "Batch:40\n",
      "d_loss_real:1.2181620597839355\n",
      "d_loss_fake:0.03960661590099335\n",
      "d_loss_wrong:1.025755524635315\n",
      "d_loss:0.875421553850174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss:[2.010426, 1.9664884, 0.02196882]\n",
      "Batch:41\n",
      "d_loss_real:1.068000316619873\n",
      "d_loss_fake:0.009768003597855568\n",
      "d_loss_wrong:0.7064680457115173\n",
      "d_loss:0.7130591720342636\n",
      "g_loss:[1.4422128, 1.3886604, 0.02677618]\n",
      "Batch:42\n",
      "d_loss_real:1.260937213897705\n",
      "d_loss_fake:0.006781344767659903\n",
      "d_loss_wrong:0.7031331062316895\n",
      "d_loss:0.8079472184181213\n",
      "g_loss:[0.85796547, 0.81454444, 0.021710526]\n",
      "Batch:43\n",
      "d_loss_real:0.9490203261375427\n",
      "d_loss_fake:0.017877476289868355\n",
      "d_loss_wrong:0.7453889846801758\n",
      "d_loss:0.6653267741203308\n",
      "g_loss:[1.0810131, 1.0233203, 0.02884638]\n",
      "Batch:44\n",
      "d_loss_real:0.8920172452926636\n",
      "d_loss_fake:0.027011647820472717\n",
      "d_loss_wrong:0.8001278638839722\n",
      "d_loss:0.6527934968471527\n",
      "g_loss:[1.4803307, 1.4326005, 0.023865081]\n",
      "Batch:45\n",
      "d_loss_real:0.9976023435592651\n",
      "d_loss_fake:0.024857187643647194\n",
      "d_loss_wrong:0.6787723898887634\n",
      "d_loss:0.6747085601091385\n",
      "g_loss:[1.4116514, 1.3600016, 0.02582493]\n",
      "Batch:46\n",
      "d_loss_real:1.024959683418274\n",
      "d_loss_fake:0.0673062652349472\n",
      "d_loss_wrong:0.6762680411338806\n",
      "d_loss:0.6983734220266342\n",
      "g_loss:[0.9647301, 0.91104543, 0.026842318]\n",
      "Batch:47\n",
      "d_loss_real:1.0356136560440063\n",
      "d_loss_fake:0.037634581327438354\n",
      "d_loss_wrong:0.7305335402488708\n",
      "d_loss:0.7098488509654999\n",
      "g_loss:[1.274414, 1.2249599, 0.024727033]\n",
      "Batch:48\n",
      "d_loss_real:1.0260415077209473\n",
      "d_loss_fake:0.01767936907708645\n",
      "d_loss_wrong:0.7205009460449219\n",
      "d_loss:0.6975658386945724\n",
      "g_loss:[1.1299578, 1.0817473, 0.024105277]\n",
      "Batch:49\n",
      "d_loss_real:0.972075879573822\n",
      "d_loss_fake:0.04448602721095085\n",
      "d_loss_wrong:0.7015547752380371\n",
      "d_loss:0.6725481450557709\n",
      "g_loss:[1.1399201, 1.0829545, 0.02848282]\n",
      "Batch:50\n",
      "d_loss_real:1.028949499130249\n",
      "d_loss_fake:0.11164683103561401\n",
      "d_loss_wrong:0.6437099575996399\n",
      "d_loss:0.703313946723938\n",
      "g_loss:[1.5829759, 1.5427823, 0.020096779]\n",
      "Batch:51\n",
      "d_loss_real:1.0659703016281128\n",
      "d_loss_fake:0.12599383294582367\n",
      "d_loss_wrong:0.6610390543937683\n",
      "d_loss:0.7297433763742447\n",
      "g_loss:[1.5012394, 1.4618504, 0.019694522]\n",
      "Batch:52\n",
      "d_loss_real:1.0422024726867676\n",
      "d_loss_fake:0.07374843955039978\n",
      "d_loss_wrong:0.7050697803497314\n",
      "d_loss:0.7158057987689972\n",
      "g_loss:[1.1897298, 1.1507322, 0.01949882]\n",
      "Batch:53\n",
      "d_loss_real:1.2516741752624512\n",
      "d_loss_fake:0.051598094403743744\n",
      "d_loss_wrong:0.6868752837181091\n",
      "d_loss:0.8104554265737534\n",
      "g_loss:[1.1524919, 1.1101366, 0.021177646]\n",
      "Batch:54\n",
      "d_loss_real:0.9075080156326294\n",
      "d_loss_fake:0.04836631193757057\n",
      "d_loss_wrong:0.7791392803192139\n",
      "d_loss:0.6606304049491882\n",
      "g_loss:[0.80574816, 0.77114606, 0.017301062]\n",
      "Batch:55\n",
      "d_loss_real:0.9712294340133667\n",
      "d_loss_fake:0.06993471831083298\n",
      "d_loss_wrong:0.6788105368614197\n",
      "d_loss:0.6728010326623917\n",
      "g_loss:[1.3209296, 1.2772241, 0.02185278]\n",
      "Batch:56\n",
      "d_loss_real:1.0705692768096924\n",
      "d_loss_fake:0.012547706253826618\n",
      "d_loss_wrong:0.7856374979019165\n",
      "d_loss:0.7348309457302094\n",
      "g_loss:[1.0973774, 1.0526278, 0.022374833]\n",
      "Batch:57\n",
      "d_loss_real:1.1099456548690796\n",
      "d_loss_fake:0.0184931717813015\n",
      "d_loss_wrong:0.6830214858055115\n",
      "d_loss:0.7303514927625656\n",
      "g_loss:[1.0420549, 0.9911184, 0.025468275]\n",
      "Batch:58\n",
      "d_loss_real:0.9258829355239868\n",
      "d_loss_fake:0.009322620928287506\n",
      "d_loss_wrong:0.7734662890434265\n",
      "d_loss:0.6586387008428574\n",
      "g_loss:[0.87163866, 0.8283677, 0.021635478]\n",
      "Batch:59\n",
      "d_loss_real:0.9759035110473633\n",
      "d_loss_fake:0.004556089639663696\n",
      "d_loss_wrong:0.7765039205551147\n",
      "d_loss:0.6832167506217957\n",
      "g_loss:[0.7728405, 0.7353974, 0.018721547]\n",
      "Batch:60\n",
      "d_loss_real:0.9491578340530396\n",
      "d_loss_fake:0.009850692003965378\n",
      "d_loss_wrong:0.7664344906806946\n",
      "d_loss:0.668650209903717\n",
      "g_loss:[0.9924479, 0.9540117, 0.019218113]\n",
      "Batch:61\n",
      "d_loss_real:0.970805287361145\n",
      "d_loss_fake:0.007597986608743668\n",
      "d_loss_wrong:0.7785557508468628\n",
      "d_loss:0.6819410771131516\n",
      "g_loss:[0.7954174, 0.7635642, 0.0159266]\n",
      "Batch:62\n",
      "d_loss_real:0.9623469710350037\n",
      "d_loss_fake:0.00346884923055768\n",
      "d_loss_wrong:0.7286328077316284\n",
      "d_loss:0.6641989052295685\n",
      "g_loss:[0.79257655, 0.7564592, 0.018058702]\n",
      "Batch:63\n",
      "d_loss_real:1.018431305885315\n",
      "d_loss_fake:0.001962450332939625\n",
      "d_loss_wrong:0.729220986366272\n",
      "d_loss:0.6920115053653717\n",
      "g_loss:[0.615675, 0.5752359, 0.020219548]\n",
      "Batch:64\n",
      "d_loss_real:0.9564318656921387\n",
      "d_loss_fake:0.001529137254692614\n",
      "d_loss_wrong:0.7357659339904785\n",
      "d_loss:0.6625397056341171\n",
      "g_loss:[0.622844, 0.583879, 0.019482497]\n",
      "Batch:65\n",
      "d_loss_real:0.9818774461746216\n",
      "d_loss_fake:0.006125493906438351\n",
      "d_loss_wrong:0.7897405624389648\n",
      "d_loss:0.6899052411317825\n",
      "g_loss:[0.67221093, 0.61769474, 0.027258113]\n",
      "Batch:66\n",
      "d_loss_real:0.8632999658584595\n",
      "d_loss_fake:0.005273421294987202\n",
      "d_loss_wrong:0.7611163258552551\n",
      "d_loss:0.6232474148273468\n",
      "g_loss:[0.6920011, 0.6586627, 0.016669214]\n",
      "Batch:67\n",
      "d_loss_real:1.000748634338379\n",
      "d_loss_fake:0.005746704526245594\n",
      "d_loss_wrong:0.6822822690010071\n",
      "d_loss:0.6723815649747849\n",
      "g_loss:[0.5095117, 0.47877398, 0.015368862]\n",
      "Batch:68\n",
      "d_loss_real:0.9456193447113037\n",
      "d_loss_fake:0.0026178210973739624\n",
      "d_loss_wrong:0.7784430384635925\n",
      "d_loss:0.6680748909711838\n",
      "g_loss:[0.864742, 0.82917136, 0.017785307]\n",
      "Batch:69\n",
      "d_loss_real:0.992877721786499\n",
      "d_loss_fake:0.01842408999800682\n",
      "d_loss_wrong:0.9617095589637756\n",
      "d_loss:0.7414722740650177\n",
      "g_loss:[0.5970483, 0.57051694, 0.0132656675]\n",
      "Batch:70\n",
      "d_loss_real:0.9115802645683289\n",
      "d_loss_fake:0.002781847259029746\n",
      "d_loss_wrong:0.7265766859054565\n",
      "d_loss:0.6381297707557678\n",
      "g_loss:[0.7775935, 0.7449595, 0.016317021]\n",
      "Batch:71\n",
      "d_loss_real:0.9809088110923767\n",
      "d_loss_fake:0.002315595280379057\n",
      "d_loss_wrong:0.6465930342674255\n",
      "d_loss:0.6526815593242645\n",
      "g_loss:[0.59747034, 0.56350577, 0.016982289]\n",
      "Batch:72\n",
      "d_loss_real:0.9694995880126953\n",
      "d_loss_fake:0.0030649942345917225\n",
      "d_loss_wrong:0.701085090637207\n",
      "d_loss:0.6607873141765594\n",
      "g_loss:[0.68491924, 0.6558647, 0.01452725]\n",
      "Batch:73\n",
      "d_loss_real:0.8792914152145386\n",
      "d_loss_fake:0.001033733133226633\n",
      "d_loss_wrong:0.7511858344078064\n",
      "d_loss:0.6277005970478058\n",
      "g_loss:[0.58948135, 0.5572259, 0.01612775]\n",
      "Batch:74\n",
      "d_loss_real:0.9693567752838135\n",
      "d_loss_fake:0.0021465998142957687\n",
      "d_loss_wrong:0.7316457629203796\n",
      "d_loss:0.6681264787912369\n",
      "g_loss:[0.5040863, 0.4723348, 0.015875759]\n",
      "Batch:75\n",
      "d_loss_real:0.9445201754570007\n",
      "d_loss_fake:0.0051989322528243065\n",
      "d_loss_wrong:0.7238080501556396\n",
      "d_loss:0.6545118391513824\n",
      "g_loss:[0.47984058, 0.44358826, 0.018126152]\n",
      "Batch:76\n",
      "d_loss_real:0.9362890720367432\n",
      "d_loss_fake:0.007681222632527351\n",
      "d_loss_wrong:0.6943262219429016\n",
      "d_loss:0.6436464041471481\n",
      "g_loss:[0.48443907, 0.45450413, 0.014967467]\n",
      "Batch:77\n",
      "d_loss_real:0.906456470489502\n",
      "d_loss_fake:0.006080298684537411\n",
      "d_loss_wrong:0.7401375770568848\n",
      "d_loss:0.6397826969623566\n",
      "g_loss:[0.44783586, 0.4194733, 0.014181294]\n",
      "Batch:78\n",
      "d_loss_real:0.8985594511032104\n",
      "d_loss_fake:0.0027216128073632717\n",
      "d_loss_wrong:0.7305446863174438\n",
      "d_loss:0.6325962990522385\n",
      "g_loss:[0.5146346, 0.4828089, 0.01591286]\n",
      "Batch:79\n",
      "d_loss_real:0.9030000567436218\n",
      "d_loss_fake:0.00210373941808939\n",
      "d_loss_wrong:0.6986432075500488\n",
      "d_loss:0.62668676674366\n",
      "g_loss:[0.5499582, 0.51614803, 0.0169051]\n",
      "Batch:80\n",
      "d_loss_real:0.8749310970306396\n",
      "d_loss_fake:0.0019269814947620034\n",
      "d_loss_wrong:0.7159368991851807\n",
      "d_loss:0.6169315129518509\n",
      "g_loss:[0.6530614, 0.62308335, 0.014989015]\n",
      "Batch:81\n",
      "d_loss_real:0.9192343950271606\n",
      "d_loss_fake:0.002556807128712535\n",
      "d_loss_wrong:0.6700697541236877\n",
      "d_loss:0.6277738362550735\n",
      "g_loss:[0.68760407, 0.65823054, 0.014686767]\n",
      "Batch:82\n",
      "d_loss_real:1.0338547229766846\n",
      "d_loss_fake:0.003880967851728201\n",
      "d_loss_wrong:0.7106390595436096\n",
      "d_loss:0.6955573707818985\n",
      "g_loss:[0.42857194, 0.39793378, 0.015319081]\n",
      "Batch:83\n",
      "d_loss_real:0.8154193162918091\n",
      "d_loss_fake:0.0055490536615252495\n",
      "d_loss_wrong:0.7188761830329895\n",
      "d_loss:0.5888159722089767\n",
      "g_loss:[0.5479272, 0.51958334, 0.014171932]\n",
      "Batch:84\n",
      "d_loss_real:0.8715088367462158\n",
      "d_loss_fake:0.0042358022183179855\n",
      "d_loss_wrong:0.7350645661354065\n",
      "d_loss:0.6205795109272003\n",
      "g_loss:[0.6407653, 0.61282206, 0.013971612]\n",
      "Batch:85\n",
      "d_loss_real:0.893203854560852\n",
      "d_loss_fake:0.007430491037666798\n",
      "d_loss_wrong:0.7029012441635132\n",
      "d_loss:0.624184861779213\n",
      "g_loss:[0.55555695, 0.52708244, 0.014237255]\n",
      "Batch:86\n",
      "d_loss_real:0.9154181480407715\n",
      "d_loss_fake:0.0026411954313516617\n",
      "d_loss_wrong:0.6885421872138977\n",
      "d_loss:0.630504921078682\n",
      "g_loss:[0.5418944, 0.5175756, 0.012159387]\n",
      "Batch:87\n",
      "d_loss_real:0.9026538729667664\n",
      "d_loss_fake:0.004454615991562605\n",
      "d_loss_wrong:0.683977484703064\n",
      "d_loss:0.6234349608421326\n",
      "g_loss:[0.42269856, 0.3922181, 0.015240225]\n",
      "Batch:88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_loss_real:0.9351787567138672\n",
      "d_loss_fake:0.0031939162872731686\n",
      "d_loss_wrong:0.7174118161201477\n",
      "d_loss:0.6477408111095428\n",
      "g_loss:[0.56401443, 0.530752, 0.016631221]\n",
      "Batch:89\n",
      "d_loss_real:0.9147741794586182\n",
      "d_loss_fake:0.0029751546680927277\n",
      "d_loss_wrong:0.7965503334999084\n",
      "d_loss:0.6572684645652771\n",
      "g_loss:[0.5864933, 0.54185975, 0.02231678]\n",
      "Batch:90\n",
      "d_loss_real:0.8962128162384033\n",
      "d_loss_fake:0.003485442139208317\n",
      "d_loss_wrong:0.742505669593811\n",
      "d_loss:0.6346041858196259\n",
      "g_loss:[0.5362618, 0.49564072, 0.020310549]\n",
      "Batch:91\n",
      "d_loss_real:0.8897666931152344\n",
      "d_loss_fake:0.0018221394857391715\n",
      "d_loss_wrong:0.7450000643730164\n",
      "d_loss:0.6315888911485672\n",
      "g_loss:[0.4887724, 0.45937043, 0.014700973]\n",
      "Batch:92\n",
      "d_loss_real:1.00399649143219\n",
      "d_loss_fake:0.0016987576382234693\n",
      "d_loss_wrong:0.8031702041625977\n",
      "d_loss:0.703215479850769\n",
      "g_loss:[0.60102004, 0.567453, 0.016783504]\n",
      "Batch:93\n",
      "d_loss_real:0.9145236611366272\n",
      "d_loss_fake:0.003657488152384758\n",
      "d_loss_wrong:0.7024654150009155\n",
      "d_loss:0.6337925493717194\n",
      "g_loss:[0.8346956, 0.8007897, 0.016952947]\n",
      "Batch:94\n",
      "d_loss_real:0.9097657203674316\n",
      "d_loss_fake:0.009657611139118671\n",
      "d_loss_wrong:0.7370263934135437\n",
      "d_loss:0.6415538638830185\n",
      "g_loss:[0.48251593, 0.4337231, 0.02439642]\n",
      "Batch:95\n",
      "d_loss_real:0.9309677481651306\n",
      "d_loss_fake:0.005939493887126446\n",
      "d_loss_wrong:0.6834121942520142\n",
      "d_loss:0.6378217935562134\n",
      "g_loss:[0.61088675, 0.5717437, 0.01957152]\n",
      "Batch:96\n",
      "d_loss_real:0.8415641188621521\n",
      "d_loss_fake:0.003362431190907955\n",
      "d_loss_wrong:0.6949661374092102\n",
      "d_loss:0.5953641980886459\n",
      "g_loss:[0.6638169, 0.6173272, 0.023244862]\n",
      "Batch:97\n",
      "d_loss_real:0.878750741481781\n",
      "d_loss_fake:0.004218392074108124\n",
      "d_loss_wrong:0.6926579475402832\n",
      "d_loss:0.6135944575071335\n",
      "g_loss:[0.637124, 0.59561324, 0.020755371]\n",
      "Batch:98\n",
      "d_loss_real:0.9146043062210083\n",
      "d_loss_fake:0.0010115363402292132\n",
      "d_loss_wrong:0.7151597738265991\n",
      "d_loss:0.6363449841737747\n",
      "g_loss:[0.6006904, 0.5581167, 0.021286875]\n",
      "Batch:99\n",
      "d_loss_real:0.9058066606521606\n",
      "d_loss_fake:0.0015363198472186923\n",
      "d_loss_wrong:0.6734060049057007\n",
      "d_loss:0.6216389089822769\n",
      "g_loss:[0.57161427, 0.5330938, 0.019260228]\n",
      "Batch:100\n",
      "d_loss_real:0.879126787185669\n",
      "d_loss_fake:0.0017545451410114765\n",
      "d_loss_wrong:0.6850038766860962\n",
      "d_loss:0.6112529933452606\n",
      "g_loss:[0.5071763, 0.47357845, 0.01679892]\n",
      "Batch:101\n",
      "d_loss_real:0.8978489637374878\n",
      "d_loss_fake:0.005734086502343416\n",
      "d_loss_wrong:0.7305511832237244\n",
      "d_loss:0.6329957991838455\n",
      "g_loss:[0.4850556, 0.45206308, 0.01649625]\n",
      "Batch:102\n",
      "d_loss_real:0.9424213171005249\n",
      "d_loss_fake:0.0018406510353088379\n",
      "d_loss_wrong:0.7113311290740967\n",
      "d_loss:0.6495036035776138\n",
      "g_loss:[0.45607036, 0.42789865, 0.0140858665]\n",
      "Batch:103\n",
      "d_loss_real:0.913198709487915\n",
      "d_loss_fake:0.00491445604711771\n",
      "d_loss_wrong:0.6780657768249512\n",
      "d_loss:0.6273444145917892\n",
      "g_loss:[0.45526296, 0.4264521, 0.014405436]\n",
      "Batch:104\n",
      "d_loss_real:0.9188573360443115\n",
      "d_loss_fake:0.007293787784874439\n",
      "d_loss_wrong:0.7466131448745728\n",
      "d_loss:0.6479053944349289\n",
      "g_loss:[0.3958923, 0.37052265, 0.012684824]\n",
      "Batch:105\n",
      "d_loss_real:0.9354413151741028\n",
      "d_loss_fake:0.0011809280840680003\n",
      "d_loss_wrong:0.7353867888450623\n",
      "d_loss:0.6518625915050507\n",
      "g_loss:[0.5346588, 0.5106772, 0.0119907735]\n",
      "Batch:106\n",
      "d_loss_real:0.87193763256073\n",
      "d_loss_fake:0.0029132706113159657\n",
      "d_loss_wrong:0.6924830675125122\n",
      "d_loss:0.6098179072141647\n",
      "g_loss:[0.43872133, 0.4164793, 0.011121023]\n",
      "Batch:107\n",
      "d_loss_real:0.9154735803604126\n",
      "d_loss_fake:0.003430214710533619\n",
      "d_loss_wrong:0.7111628651618958\n",
      "d_loss:0.636385053396225\n",
      "g_loss:[0.46818578, 0.44413036, 0.012027709]\n",
      "Batch:108\n",
      "d_loss_real:0.90511155128479\n",
      "d_loss_fake:0.002409081906080246\n",
      "d_loss_wrong:0.6936174035072327\n",
      "d_loss:0.6265624016523361\n",
      "g_loss:[0.4361083, 0.41283196, 0.011638167]\n",
      "Batch:109\n",
      "d_loss_real:0.9043478965759277\n",
      "d_loss_fake:0.005938787944614887\n",
      "d_loss_wrong:0.706447958946228\n",
      "d_loss:0.6302706301212311\n",
      "g_loss:[0.48223272, 0.4598722, 0.011180265]\n",
      "Batch:110\n",
      "d_loss_real:0.8665133118629456\n",
      "d_loss_fake:0.0013377612922340631\n",
      "d_loss_wrong:0.6987742781639099\n",
      "d_loss:0.608284667134285\n",
      "g_loss:[0.41702828, 0.3883077, 0.014360289]\n",
      "Batch:111\n",
      "d_loss_real:0.8659988641738892\n",
      "d_loss_fake:0.001696119550615549\n",
      "d_loss_wrong:0.6916075348854065\n",
      "d_loss:0.6063253432512283\n",
      "g_loss:[0.51509464, 0.4872383, 0.013928179]\n",
      "Batch:112\n",
      "d_loss_real:0.8806629180908203\n",
      "d_loss_fake:0.0022601066157221794\n",
      "d_loss_wrong:0.7201412916183472\n",
      "d_loss:0.6209318041801453\n",
      "g_loss:[0.45598987, 0.4223926, 0.016798625]\n",
      "Batch:113\n",
      "d_loss_real:0.868027925491333\n",
      "d_loss_fake:0.004927447531372309\n",
      "d_loss_wrong:0.7020356059074402\n",
      "d_loss:0.6107547283172607\n",
      "g_loss:[0.45351353, 0.42155218, 0.015980672]\n",
      "Batch:114\n",
      "d_loss_real:0.8591443300247192\n",
      "d_loss_fake:0.0013589505106210709\n",
      "d_loss_wrong:0.668783962726593\n",
      "d_loss:0.5971078872680664\n",
      "g_loss:[0.5852958, 0.55102384, 0.01713599]\n",
      "Batch:115\n",
      "d_loss_real:0.8916887640953064\n",
      "d_loss_fake:0.001477915677241981\n",
      "d_loss_wrong:0.6947029232978821\n",
      "d_loss:0.6198895871639252\n",
      "g_loss:[0.4612956, 0.4355216, 0.012887002]\n",
      "Batch:116\n",
      "d_loss_real:0.9294010996818542\n",
      "d_loss_fake:0.004394909366965294\n",
      "d_loss_wrong:0.7094796895980835\n",
      "d_loss:0.6431691944599152\n",
      "g_loss:[0.41290244, 0.38660306, 0.013149691]\n",
      "Batch:117\n",
      "d_loss_real:0.8910236954689026\n",
      "d_loss_fake:0.0031048187520354986\n",
      "d_loss_wrong:0.7057283520698547\n",
      "d_loss:0.6227201372385025\n",
      "g_loss:[0.4538823, 0.43298477, 0.010448771]\n",
      "Batch:118\n",
      "d_loss_real:0.8631981015205383\n",
      "d_loss_fake:0.0028545751702040434\n",
      "d_loss_wrong:0.6921687126159668\n",
      "d_loss:0.6053548753261566\n",
      "g_loss:[0.4635965, 0.44372788, 0.009934311]\n",
      "Batch:119\n",
      "d_loss_real:0.8664327263832092\n",
      "d_loss_fake:0.0022784722968935966\n",
      "d_loss_wrong:0.6978477835655212\n",
      "d_loss:0.608247920870781\n",
      "g_loss:[0.45343652, 0.4306249, 0.011405807]\n",
      "Batch:120\n",
      "d_loss_real:0.8894892930984497\n",
      "d_loss_fake:0.002793633146211505\n",
      "d_loss_wrong:0.684052050113678\n",
      "d_loss:0.6164560616016388\n",
      "g_loss:[0.4213334, 0.39618528, 0.012574065]\n",
      "Batch:121\n",
      "d_loss_real:0.8970390558242798\n",
      "d_loss_fake:0.002627317328006029\n",
      "d_loss_wrong:0.7160282731056213\n",
      "d_loss:0.6281834244728088\n",
      "g_loss:[0.36717957, 0.34781837, 0.009680596]\n",
      "Batch:122\n",
      "d_loss_real:0.8579959869384766\n",
      "d_loss_fake:0.004072482697665691\n",
      "d_loss_wrong:0.6998030543327332\n",
      "d_loss:0.6049668788909912\n",
      "g_loss:[0.45069784, 0.4289704, 0.010863721]\n",
      "Batch:123\n",
      "d_loss_real:0.993346631526947\n",
      "d_loss_fake:0.002633738797158003\n",
      "d_loss_wrong:0.7237250208854675\n",
      "d_loss:0.6782630085945129\n",
      "g_loss:[0.3954055, 0.37582177, 0.0097918715]\n",
      "Batch:124\n",
      "d_loss_real:0.9160635471343994\n",
      "d_loss_fake:0.0031560356728732586\n",
      "d_loss_wrong:0.6662725806236267\n",
      "d_loss:0.6253889203071594\n",
      "g_loss:[0.42086533, 0.4033174, 0.008773969]\n",
      "Batch:125\n",
      "d_loss_real:0.8230177164077759\n",
      "d_loss_fake:0.003032891545444727\n",
      "d_loss_wrong:0.7070500254631042\n",
      "d_loss:0.5890295803546906\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_dir = \"./birds/\"\n",
    "    train_dir = data_dir + \"train\"\n",
    "    test_dir = data_dir + \"test\"\n",
    "    image_size = 64\n",
    "    batch_size = 64\n",
    "    z_dim = 100\n",
    "    stage1_generator_lr = 0.0002\n",
    "    stage1_discriminator_lr = 0.0002\n",
    "    stage1_lr_decay_step = 600\n",
    "    epochs = 2\n",
    "    condition_dim = 128\n",
    "\n",
    "    embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "    embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\n",
    "    filenames_file_path_train = train_dir + \"/filenames.pickle\"\n",
    "    filenames_file_path_test = test_dir + \"/filenames.pickle\"\n",
    "\n",
    "    class_info_file_path_train = train_dir + \"/class_info.pickle\"\n",
    "    class_info_file_path_test = test_dir + \"/class_info.pickle\"\n",
    "\n",
    "    cub_dataset_dir = \"./CUB_200_2011\"\n",
    "    \n",
    "    # Define optimizers\n",
    "    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "    \"\"\"\"\n",
    "    Load datasets\n",
    "    \"\"\"\n",
    "    X_train, y_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\n",
    "                                                      class_info_file_path=class_info_file_path_train,\n",
    "                                                      cub_dataset_dir=cub_dataset_dir,\n",
    "                                                      embeddings_file_path=embeddings_file_path_train,\n",
    "                                                      image_size=(64, 64))\n",
    "\n",
    "    X_test, y_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\n",
    "                                                   class_info_file_path=class_info_file_path_test,\n",
    "                                                   cub_dataset_dir=cub_dataset_dir,\n",
    "                                                   embeddings_file_path=embeddings_file_path_test,\n",
    "                                                   image_size=(64, 64))\n",
    "\n",
    "    \"\"\"\n",
    "    Build and compile networks\n",
    "    \"\"\"\n",
    "    ca_model = build_ca_model()\n",
    "    ca_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "    stage1_dis = build_stage1_discriminator()\n",
    "    stage1_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n",
    "\n",
    "    stage1_gen = build_stage1_generator()\n",
    "    stage1_gen.compile(loss=\"mse\", optimizer=gen_optimizer)\n",
    "\n",
    "    embedding_compressor_model = build_embedding_compressor_model()\n",
    "    embedding_compressor_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "    adversarial_model = build_adversarial_model(gen_model=stage1_gen, dis_model=stage1_dis)\n",
    "    adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1, 2.0],\n",
    "                              optimizer=gen_optimizer, metrics=None)\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
    "    tensorboard.set_model(stage1_gen)\n",
    "    tensorboard.set_model(stage1_dis)\n",
    "    tensorboard.set_model(ca_model)\n",
    "    tensorboard.set_model(embedding_compressor_model)\n",
    "\n",
    "    # Generate an array containing real and fake values\n",
    "    # Apply label smoothing as well\n",
    "    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n",
    "    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"========================================\")\n",
    "        print(\"Epoch is:\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0] / batch_size))\n",
    "\n",
    "        gen_losses = []\n",
    "        dis_losses = []\n",
    "\n",
    "        # Load data and train model\n",
    "        number_of_batches = int(X_train.shape[0] / batch_size)\n",
    "        for index in range(number_of_batches):\n",
    "            print(\"Batch:{}\".format(index+1))\n",
    "            \n",
    "            \"\"\"\n",
    "            Train the discriminator network\n",
    "            \"\"\"\n",
    "            # Sample a batch of data\n",
    "            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
    "            image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n",
    "            image_batch = (image_batch - 127.5) / 127.5\n",
    "\n",
    "            # Generate fake images\n",
    "            fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n",
    "\n",
    "            # Generate compressed embeddings\n",
    "            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n",
    "            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n",
    "            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
    "\n",
    "            dis_loss_real = stage1_dis.train_on_batch([image_batch, compressed_embedding],\n",
    "                                                      np.reshape(real_labels, (batch_size, 1)))\n",
    "            dis_loss_fake = stage1_dis.train_on_batch([fake_images, compressed_embedding],\n",
    "                                                      np.reshape(fake_labels, (batch_size, 1)))\n",
    "            dis_loss_wrong = stage1_dis.train_on_batch([image_batch[:(batch_size - 1)], compressed_embedding[1:]],\n",
    "                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\n",
    "\n",
    "            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))\n",
    "\n",
    "            print(\"d_loss_real:{}\".format(dis_loss_real))\n",
    "            print(\"d_loss_fake:{}\".format(dis_loss_fake))\n",
    "            print(\"d_loss_wrong:{}\".format(dis_loss_wrong))\n",
    "            print(\"d_loss:{}\".format(d_loss))\n",
    "\n",
    "            \"\"\"\n",
    "            Train the generator network \n",
    "            \"\"\"\n",
    "            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],[K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n",
    "            print(\"g_loss:{}\".format(g_loss))\n",
    "\n",
    "            dis_losses.append(d_loss)\n",
    "            gen_losses.append(g_loss)\n",
    "\n",
    "        \"\"\"\n",
    "        Save losses to Tensorboard after each epoch\n",
    "        \"\"\"\n",
    "        write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n",
    "        write_log(tensorboard, 'generator_loss', np.mean(gen_losses[0]), epoch)\n",
    "        \n",
    "        # Generate and save images after every 2nd epoch\n",
    "        if epoch % 2 == 0:\n",
    "            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
    "            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
    "            embedding_batch = embeddings_test[0:batch_size]\n",
    "            fake_images, _ = stage1_gen.predict_on_batch([embedding_batch, z_noise2])\n",
    "\n",
    "            # Save images\n",
    "            for i, img in enumerate(fake_images[:10]):\n",
    "                save_rgb_img(img, \"results/gen_{}_{}.png\".format(epoch, i))\n",
    "\n",
    "    # Save models\n",
    "    stage1_gen.save_weights(\"stage1_gen.h5\")\n",
    "    stage1_dis.save_weights(\"stage1_dis.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QCYyOZMRXzfv"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ot1xZ3odm6eI"
   },
   "outputs": [],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nGYJWLTGm9R4",
    "outputId": "3192cc05-1a55-4a8e-9f5f-1e13d6d90683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1mzYY3DjNTzxlilPfsIo_hNt0SW3Bba-K\n"
     ]
    }
   ],
   "source": [
    "# Create & upload a file.\n",
    "uploaded = drive.CreateFile({'title': 'stage1_dis.h5'})\n",
    "uploaded.SetContentFile('stage1_dis.h5')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "glMY1sSNnFQi",
    "outputId": "f71faa05-684d-486f-99fd-d8da179efdf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1j6UN3VOUMg-chLY0Pf5lfiVcQFKmSei-\n"
     ]
    }
   ],
   "source": [
    "# Create & upload a file.\n",
    "uploaded = drive.CreateFile({'title': 'stage1_gen.h5'})\n",
    "uploaded.SetContentFile('stage1_gen.h5')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfRs1DsqnJVc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "psC9UHjzliA1",
    "XZybHodapH3H",
    "ODvYdkGtpGKJ",
    "eNBHRmpqpZgo"
   ],
   "include_colab_link": true,
   "name": "stackgan_stage_I_imp.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
