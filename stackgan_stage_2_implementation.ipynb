{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrrajatgarg/StackGAN/blob/master/stackgan_stage_2_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "54x-F4lPnnnX",
    "outputId": "8049bc6b-4173-4913-e6fd-5e123251a147"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-70089a784baf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrive\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGoogleDrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WWuXYgqnrT9"
   },
   "outputs": [],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a89wjzh0nrRm",
    "outputId": "393bf06a-3d2e-4d89-8acd-4018a9c05d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1mzYY3DjNTzxlilPfsIo_hNt0SW3Bba-K\n"
     ]
    }
   ],
   "source": [
    "link = 'https://drive.google.com/open?id=1mzYY3DjNTzxlilPfsIo_hNt0SW3Bba-K'\n",
    "\n",
    "fluff, id = link.split('=')\n",
    "\n",
    "print (id) # Verify that you have everything after '='\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('stage1_dis.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GwQrHLjOnrPP",
    "outputId": "15c04ac6-00a4-458c-9bf7-9ab00ff1b5ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1j6UN3VOUMg-chLY0Pf5lfiVcQFKmSei-\n"
     ]
    }
   ],
   "source": [
    "link = 'https://drive.google.com/open?id=1j6UN3VOUMg-chLY0Pf5lfiVcQFKmSei-'\n",
    "\n",
    "fluff, id = link.split('=')\n",
    "\n",
    "print (id) # Verify that you have everything after '='\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('stage1_gen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kY8VPrPYnrM7",
    "outputId": "514c2529-2d14-40e0-94c5-f0614d45782e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0B3y_msrWZaXLT1BZdVdycDY5TEE\n"
     ]
    }
   ],
   "source": [
    "link = 'https://drive.google.com/open?id=0B3y_msrWZaXLT1BZdVdycDY5TEE'\n",
    "\n",
    "fluff, id = link.split('=')\n",
    "\n",
    "print (id) # Verify that you have everything after '='\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('birds.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bjnrMU8SnrKN"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('/content/birds.zip', 'r')\n",
    "zip_ref.extractall('/content/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eSjwyTALnrG8",
    "outputId": "48396d69-7123-4916-aef1-a9e62b7ff715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adc.json  birds  birds.zip  sample_data  stage1_dis.h5\tstage1_gen.h5\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "xqQOAagVoyFQ",
    "outputId": "252c9ee5-4bbd-43ae-d22b-11bd46183ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-02-17 18:07:37--  http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz\n",
      "Resolving www.vision.caltech.edu (www.vision.caltech.edu)... 34.208.54.77\n",
      "Connecting to www.vision.caltech.edu (www.vision.caltech.edu)|34.208.54.77|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1150585339 (1.1G) [application/x-tar]\n",
      "Saving to: ‘CUB_200_2011.tgz’\n",
      "\n",
      "CUB_200_2011.tgz    100%[===================>]   1.07G  21.6MB/s    in 49s     \n",
      "\n",
      "2019-02-17 18:08:27 (22.2 MB/s) - ‘CUB_200_2011.tgz’ saved [1150585339/1150585339]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5GKxn7nNoyKr"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "tar = tarfile.open(\"CUB_200_2011.tgz\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Ul0swQ5eoyTC",
    "outputId": "ec4aeaeb-12b0-4917-e81d-3057adf971ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adc.json\tbirds\t   CUB_200_2011      sample_data    stage1_gen.h5\n",
      "attributes.txt\tbirds.zip  CUB_200_2011.tgz  stage1_dis.h5\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBQ7TtwcoyZV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzKSvJnRnrES"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2frYuh_BIW8J",
    "outputId": "ea19ceb5-46e8-44e1-cff1-56b1dd3d7828"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\n",
    "    concatenate, Flatten, Lambda, Concatenate, ZeroPadding2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMbKGBagIg2t"
   },
   "outputs": [],
   "source": [
    "def build_ca_model():\n",
    "    \"\"\"\n",
    "    Get conditioning augmentation model.\n",
    "    Takes an embedding of shape (1024,) and returns a tensor of shape (256,)\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    x = Dense(256)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    model = Model(inputs=[input_layer], outputs=[x])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YcZBjH3Ijid"
   },
   "outputs": [],
   "source": [
    "def build_embedding_compressor_model():\n",
    "    \"\"\"\n",
    "    Build embedding compressor model\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    x = Dense(128)(input_layer)\n",
    "    x = ReLU()(x)\n",
    "    model = Model(inputs=[input_layer], outputs=[x])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfA66frZIoat"
   },
   "outputs": [],
   "source": [
    "def generate_c(x):\n",
    "    mean = x[:, :128]\n",
    "    log_sigma = x[:, 128:]\n",
    "\n",
    "    stddev = K.exp(log_sigma)\n",
    "    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))\n",
    "    c = stddev * epsilon + mean\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LoCkwdM5LEaG"
   },
   "outputs": [],
   "source": [
    "def build_stage1_generator():\n",
    "    \"\"\"\n",
    "    Builds a generator model used in Stage-I\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    x = Dense(256)(input_layer)\n",
    "    mean_logsigma = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    c = Lambda(generate_c)(mean_logsigma)\n",
    "\n",
    "    input_layer2 = Input(shape=(100,))\n",
    "\n",
    "    gen_input = Concatenate(axis=1)([c, input_layer2])\n",
    "\n",
    "    x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = Activation(activation='tanh')(x)\n",
    "\n",
    "    stage1_gen = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma])\n",
    "    return stage1_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIIAxxYXIrbU"
   },
   "outputs": [],
   "source": [
    "def residual_block(input):\n",
    "    \"\"\"\n",
    "    Residual block in the generator network\n",
    "    \"\"\"\n",
    "    x = Conv2D(128 * 4, kernel_size=(3, 3), padding='same', strides=1)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(128 * 4, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = add([x, input])\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wADPyw3WIz8d"
   },
   "outputs": [],
   "source": [
    "def joint_block(inputs):\n",
    "    c = inputs[0]\n",
    "    x = inputs[1]\n",
    "\n",
    "    c = K.expand_dims(c, axis=1)\n",
    "    c = K.expand_dims(c, axis=1)\n",
    "    c = K.tile(c, [1, 16, 16, 1])\n",
    "    return K.concatenate([c, x], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-ETg1zJI2oB"
   },
   "outputs": [],
   "source": [
    "def build_stage2_generator():\n",
    "    \"\"\"\n",
    "    Create Stage-II generator containing the CA Augmentation Network,\n",
    "    the image encoder and the generator network\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. CA Augmentation Network\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    input_lr_images = Input(shape=(64, 64, 3))\n",
    "\n",
    "    ca = Dense(256)(input_layer)\n",
    "    mean_logsigma = LeakyReLU(alpha=0.2)(ca)\n",
    "    c = Lambda(generate_c)(mean_logsigma)\n",
    "\n",
    "    # 2. Image Encoder\n",
    "    x = ZeroPadding2D(padding=(1, 1))(input_lr_images)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = Conv2D(256, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = Conv2D(512, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # 3. Joint\n",
    "    c_code = Lambda(joint_block)([c, x])\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(c_code)\n",
    "    x = Conv2D(512, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # 4. Residual blocks\n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "\n",
    "    # 5. Upsampling blocks\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    model = Model(inputs=[input_layer, input_lr_images], outputs=[x, mean_logsigma])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fU_WINLI8Kr"
   },
   "outputs": [],
   "source": [
    "def build_stage2_discriminator():\n",
    "    \"\"\"\n",
    "    Create Stage-II discriminator network\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(256, 256, 3))\n",
    "\n",
    "    x = Conv2D(64, (4, 4), padding='same', strides=2, input_shape=(256, 256, 3), use_bias=False)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(1024, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(2048, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(1024, (1, 1), padding='same', strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(512, (1, 1), padding='same', strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x2 = Conv2D(128, (1, 1), padding='same', strides=1, use_bias=False)(x)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.2)(x2)\n",
    "\n",
    "    x2 = Conv2D(128, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.2)(x2)\n",
    "\n",
    "    x2 = Conv2D(512, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "\n",
    "    added_x = add([x, x2])\n",
    "    added_x = LeakyReLU(alpha=0.2)(added_x)\n",
    "\n",
    "    input_layer2 = Input(shape=(4, 4, 128))\n",
    "\n",
    "    merged_input = concatenate([added_x, input_layer2])\n",
    "\n",
    "    x3 = Conv2D(64 * 8, kernel_size=1, padding=\"same\", strides=1)(merged_input)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = LeakyReLU(alpha=0.2)(x3)\n",
    "    x3 = Flatten()(x3)\n",
    "    x3 = Dense(1)(x3)\n",
    "    x3 = Activation('sigmoid')(x3)\n",
    "\n",
    "    stage2_dis = Model(inputs=[input_layer, input_layer2], outputs=[x3])\n",
    "    return stage2_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_AUa6BzI_g5"
   },
   "outputs": [],
   "source": [
    "def build_adversarial_model(gen_model2, dis_model, gen_model1):\n",
    "    \"\"\"\n",
    "    Create adversarial model\n",
    "    \"\"\"\n",
    "    embeddings_input_layer = Input(shape=(1024, ))\n",
    "    noise_input_layer = Input(shape=(100, ))\n",
    "    compressed_embedding_input_layer = Input(shape=(4, 4, 128))\n",
    "\n",
    "    gen_model1.trainable = False\n",
    "    dis_model.trainable = False\n",
    "\n",
    "    lr_images, mean_logsigma1 = gen_model1([embeddings_input_layer, noise_input_layer])\n",
    "    hr_images, mean_logsigma2 = gen_model2([embeddings_input_layer, lr_images])\n",
    "    valid = dis_model([hr_images, compressed_embedding_input_layer])\n",
    "\n",
    "    model = Model(inputs=[embeddings_input_layer, noise_input_layer, compressed_embedding_input_layer], outputs=[valid, mean_logsigma2])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubzRdA4KJBzF"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset loading related methods\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_class_ids(class_info_file_path):\n",
    "    \"\"\"\n",
    "    Load class ids from class_info.pickle file\n",
    "    \"\"\"\n",
    "    with open(class_info_file_path, 'rb') as f:\n",
    "        class_ids = pickle.load(f, encoding='latin1')\n",
    "        return class_ids\n",
    "\n",
    "\n",
    "def load_embeddings(embeddings_file_path):\n",
    "    \"\"\"\n",
    "    Function to load embeddings\n",
    "    \"\"\"\n",
    "    with open(embeddings_file_path, 'rb') as f:\n",
    "        embeddings = pickle.load(f, encoding='latin1')\n",
    "        embeddings = np.array(embeddings)\n",
    "        print('embeddings: ', embeddings.shape)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def load_filenames(filenames_file_path):\n",
    "    \"\"\"\n",
    "    Load filenames.pickle file and return a list of all file names\n",
    "    \"\"\"\n",
    "    with open(filenames_file_path, 'rb') as f:\n",
    "        filenames = pickle.load(f, encoding='latin1')\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def load_bounding_boxes(dataset_dir):\n",
    "    \"\"\"\n",
    "    Load bounding boxes and return a dictionary of file names and corresponding bounding boxes\n",
    "    \"\"\"\n",
    "    # Paths\n",
    "    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n",
    "    file_paths_path = os.path.join(dataset_dir, 'images.txt')\n",
    "\n",
    "    # Read bounding_boxes.txt and images.txt file\n",
    "    df_bounding_boxes = pd.read_csv(bounding_boxes_path,\n",
    "                                    delim_whitespace=True, header=None).astype(int)\n",
    "    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n",
    "\n",
    "    # Create a list of file names\n",
    "    file_names = df_file_names[1].tolist()\n",
    "\n",
    "    # Create a dictionary of file_names and bounding boxes\n",
    "    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n",
    "\n",
    "    # Assign a bounding box to the corresponding image\n",
    "    for i in range(0, len(file_names)):\n",
    "        # Get the bounding box\n",
    "        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n",
    "        key = file_names[i][:-4]\n",
    "        filename_boundingbox_dict[key] = bounding_box\n",
    "\n",
    "    return filename_boundingbox_dict\n",
    "\n",
    "\n",
    "def get_img(img_path, bbox, image_size):\n",
    "    \"\"\"\n",
    "    Load and resize images\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    if bbox is not None:\n",
    "        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
    "        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
    "        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
    "        y1 = np.maximum(0, center_y - R)\n",
    "        y2 = np.minimum(height, center_y + R)\n",
    "        x1 = np.maximum(0, center_x - R)\n",
    "        x2 = np.minimum(width, center_x + R)\n",
    "        img = img.crop([x1, y1, x2, y2])\n",
    "    img = img.resize(image_size, PIL.Image.BILINEAR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):\n",
    "    filenames = load_filenames(filenames_file_path)\n",
    "    class_ids = load_class_ids(class_info_file_path)\n",
    "    bounding_boxes = load_bounding_boxes(cub_dataset_dir)\n",
    "    all_embeddings = load_embeddings(embeddings_file_path)\n",
    "\n",
    "    X, y, embeddings = [], [], []\n",
    "\n",
    "    print(\"All embeddings shape:\", all_embeddings.shape)\n",
    "\n",
    "    for index, filename in enumerate(filenames):\n",
    "        bounding_box = bounding_boxes[filename]\n",
    "\n",
    "        try:\n",
    "            # Load images\n",
    "            img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\n",
    "            img = get_img(img_name, bounding_box, image_size)\n",
    "\n",
    "            all_embeddings1 = all_embeddings[index, :, :]\n",
    "\n",
    "            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n",
    "            embedding = all_embeddings1[embedding_ix, :]\n",
    "\n",
    "            X.append(np.array(img))\n",
    "            y.append(class_ids[index])\n",
    "            embeddings.append(embedding)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    embeddings = np.array(embeddings)\n",
    "\n",
    "    return X, y, embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYKYJH_DJFIA"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loss functions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def KL_loss(y_true, y_pred):\n",
    "    mean = y_pred[:, :128]\n",
    "    logsigma = y_pred[:, :128]\n",
    "    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n",
    "    loss = K.mean(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def custom_generator_loss(y_true, y_pred):\n",
    "    # Calculate binary cross entropy loss\n",
    "    return K.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "\n",
    "def write_log(callback, name, loss, batch_no):\n",
    "    \"\"\"\n",
    "    Write training summary to TensorBoard\n",
    "    \"\"\"\n",
    "    summary = tf.Summary()\n",
    "    summary_value = summary.value.add()\n",
    "    summary_value.simple_value = loss\n",
    "    summary_value.tag = name\n",
    "    callback.writer.add_summary(summary, batch_no)\n",
    "    callback.writer.flush()\n",
    "\n",
    "\n",
    "def save_rgb_img(img, path):\n",
    "    \"\"\"\n",
    "    Save an rgb image\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Image\")\n",
    "\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpqeGU4wJIN3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings:  (8855, 10, 1024)\n",
      "All embeddings shape: (8855, 10, 1024)\n",
      "embeddings:  (2933, 10, 1024)\n",
      "All embeddings shape: (2933, 10, 1024)\n",
      "[Errno 2] No such file or directory: './CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0088_796133.jpg'\n",
      "embeddings:  (8855, 10, 1024)\n",
      "All embeddings shape: (8855, 10, 1024)\n",
      "embeddings:  (2933, 10, 1024)\n",
      "All embeddings shape: (2933, 10, 1024)\n",
      "[Errno 2] No such file or directory: './CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0088_796133.jpg'\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "========================================\n",
      "Epoch is: 0\n",
      "Number of batches:2213\n",
      "Batch:1\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "d_loss:5.014432907104492\n",
      "g_loss:[1.2037327, 1.1640091, 0.01986184]\n",
      "Batch:2\n",
      "d_loss:2.5597570538520813\n",
      "g_loss:[0.67134607, 0.6405882, 0.015378928]\n",
      "Batch:3\n",
      "d_loss:4.201546907424927\n",
      "g_loss:[0.4134279, 0.38597673, 0.013725577]\n",
      "Batch:4\n",
      "d_loss:2.447489857673645\n",
      "g_loss:[0.60183674, 0.5728962, 0.014470283]\n",
      "Batch:5\n",
      "d_loss:3.070249080657959\n",
      "g_loss:[1.551792, 1.5250895, 0.013351259]\n",
      "Batch:6\n",
      "d_loss:2.1383204460144043\n",
      "g_loss:[1.5096145, 1.4831821, 0.013216186]\n",
      "Batch:7\n",
      "d_loss:2.379639506340027\n",
      "g_loss:[0.67759013, 0.64376205, 0.016914032]\n",
      "Batch:8\n",
      "d_loss:2.1435739398002625\n",
      "g_loss:[0.8569833, 0.820426, 0.01827867]\n",
      "Batch:9\n",
      "d_loss:2.192521095275879\n",
      "g_loss:[0.5931518, 0.55110765, 0.021022076]\n",
      "Batch:10\n",
      "d_loss:1.0987404882907867\n",
      "g_loss:[1.3705938, 1.3302333, 0.020180218]\n",
      "Batch:11\n",
      "d_loss:1.3397624343633652\n",
      "g_loss:[1.0642155, 1.0340987, 0.0150583815]\n",
      "Batch:12\n",
      "d_loss:2.0483163744211197\n",
      "g_loss:[1.9143348, 1.8657869, 0.024273952]\n",
      "Batch:13\n",
      "d_loss:1.8382790684700012\n",
      "g_loss:[1.1115288, 1.0849078, 0.013310506]\n",
      "Batch:14\n",
      "d_loss:1.1930095553398132\n",
      "g_loss:[0.98070586, 0.9415961, 0.019554872]\n",
      "Batch:15\n",
      "d_loss:1.2900859117507935\n",
      "g_loss:[1.553256, 1.512768, 0.020244021]\n",
      "Batch:16\n",
      "d_loss:1.4826517701148987\n",
      "g_loss:[1.4721861, 1.4220141, 0.025085956]\n",
      "Batch:17\n",
      "d_loss:1.701322227716446\n",
      "g_loss:[1.3219552, 1.2877278, 0.01711366]\n",
      "Batch:18\n",
      "d_loss:1.7930719256401062\n",
      "g_loss:[0.8405312, 0.8211026, 0.009714283]\n",
      "Batch:19\n",
      "d_loss:1.677563190460205\n",
      "g_loss:[2.318783, 2.300137, 0.009322973]\n",
      "Batch:20\n",
      "d_loss:1.6513837575912476\n",
      "g_loss:[2.13068, 2.10881, 0.010935063]\n",
      "Batch:21\n",
      "d_loss:1.223431795835495\n",
      "g_loss:[0.93071795, 0.8910635, 0.019827217]\n",
      "Batch:22\n",
      "d_loss:0.8336766809225082\n",
      "g_loss:[0.6045109, 0.5886419, 0.007934501]\n",
      "Batch:23\n",
      "d_loss:0.9864640831947327\n",
      "g_loss:[0.9305436, 0.9017454, 0.014399098]\n",
      "Batch:24\n",
      "d_loss:1.3346369117498398\n",
      "g_loss:[0.84998727, 0.8260444, 0.011971458]\n",
      "Batch:25\n",
      "d_loss:1.0360671877861023\n",
      "g_loss:[0.8674022, 0.8364643, 0.0154689485]\n",
      "Batch:26\n",
      "d_loss:1.0055945813655853\n",
      "g_loss:[0.99787235, 0.97187054, 0.013000892]\n",
      "Batch:27\n",
      "d_loss:1.0691541135311127\n",
      "g_loss:[0.41235623, 0.38217735, 0.015089432]\n",
      "Batch:28\n",
      "d_loss:1.0183717012405396\n",
      "g_loss:[0.67491376, 0.64670515, 0.01410432]\n",
      "Batch:29\n",
      "d_loss:1.0980402827262878\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_dir = \"./birds/\"\n",
    "    train_dir = data_dir + \"/train\"\n",
    "    test_dir = data_dir + \"/test\"\n",
    "    hr_image_size = (256, 256)\n",
    "    lr_image_size = (64, 64)\n",
    "    batch_size = 4\n",
    "    z_dim = 100\n",
    "    stage1_generator_lr = 0.0002\n",
    "    stage1_discriminator_lr = 0.0002\n",
    "    stage1_lr_decay_step = 600\n",
    "    epochs = 2\n",
    "    condition_dim = 128\n",
    "\n",
    "    embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "    embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\n",
    "    filenames_file_path_train = train_dir + \"/filenames.pickle\"\n",
    "    filenames_file_path_test = test_dir + \"/filenames.pickle\"\n",
    "\n",
    "    class_info_file_path_train = train_dir + \"/class_info.pickle\"\n",
    "    class_info_file_path_test = test_dir + \"/class_info.pickle\"\n",
    "\n",
    "    cub_dataset_dir = \"./CUB_200_2011\"\n",
    "\n",
    "    # Define optimizers\n",
    "    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "    \"\"\"\n",
    "    Load datasets\n",
    "    \"\"\"\n",
    "    X_hr_train, y_hr_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\n",
    "                                                            class_info_file_path=class_info_file_path_train,\n",
    "                                                            cub_dataset_dir=cub_dataset_dir,\n",
    "                                                            embeddings_file_path=embeddings_file_path_train,\n",
    "                                                            image_size=(256, 256))\n",
    "\n",
    "    X_hr_test, y_hr_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\n",
    "                                                         class_info_file_path=class_info_file_path_test,\n",
    "                                                         cub_dataset_dir=cub_dataset_dir,\n",
    "                                                         embeddings_file_path=embeddings_file_path_test,\n",
    "                                                         image_size=(256, 256))\n",
    "\n",
    "    X_lr_train, y_lr_train, _ = load_dataset(filenames_file_path=filenames_file_path_train,\n",
    "                                             class_info_file_path=class_info_file_path_train,\n",
    "                                             cub_dataset_dir=cub_dataset_dir,\n",
    "                                             embeddings_file_path=embeddings_file_path_train,\n",
    "                                             image_size=(64, 64))\n",
    "\n",
    "    X_lr_test, y_lr_test, _ = load_dataset(filenames_file_path=filenames_file_path_test,\n",
    "                                           class_info_file_path=class_info_file_path_test,\n",
    "                                           cub_dataset_dir=cub_dataset_dir,\n",
    "                                           embeddings_file_path=embeddings_file_path_test,\n",
    "                                           image_size=(64, 64))\n",
    "\n",
    "    \"\"\"\n",
    "    Build and compile models\n",
    "    \"\"\"\n",
    "    stage2_dis = build_stage2_discriminator()\n",
    "    stage2_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n",
    "\n",
    "    stage1_gen = build_stage1_generator()\n",
    "    stage1_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n",
    "\n",
    "    stage1_gen.load_weights(\"stage1_gen.h5\")\n",
    "\n",
    "    stage2_gen = build_stage2_generator()\n",
    "    stage2_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n",
    "\n",
    "    embedding_compressor_model = build_embedding_compressor_model()\n",
    "    embedding_compressor_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "    adversarial_model = build_adversarial_model(stage2_gen, stage2_dis, stage1_gen)\n",
    "    adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1.0, 2.0],\n",
    "                              optimizer=gen_optimizer, metrics=None)\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
    "    tensorboard.set_model(stage2_gen)\n",
    "    tensorboard.set_model(stage2_dis)\n",
    "\n",
    "    # Generate an array containing real and fake values\n",
    "    # Apply label smoothing\n",
    "    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n",
    "    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"========================================\")\n",
    "        print(\"Epoch is:\", epoch)\n",
    "\n",
    "        gen_losses = []\n",
    "        dis_losses = []\n",
    "\n",
    "        # Load data and train model\n",
    "        number_of_batches = int(X_hr_train.shape[0] / batch_size)\n",
    "        print(\"Number of batches:{}\".format(number_of_batches))\n",
    "        for index in range(number_of_batches):\n",
    "            print(\"Batch:{}\".format(index+1))\n",
    "\n",
    "            # Create a noise vector\n",
    "            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
    "            X_hr_train_batch = X_hr_train[index * batch_size:(index + 1) * batch_size]\n",
    "            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n",
    "            X_hr_train_batch = (X_hr_train_batch - 127.5) / 127.5\n",
    "\n",
    "            # Generate fake images\n",
    "            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n",
    "            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\n",
    "\n",
    "            \"\"\"\n",
    "            4. Generate compressed embeddings\n",
    "            \"\"\"\n",
    "            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n",
    "            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n",
    "            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
    "\n",
    "            \"\"\"\n",
    "            5. Train the discriminator model\n",
    "            \"\"\"\n",
    "            dis_loss_real = stage2_dis.train_on_batch([X_hr_train_batch, compressed_embedding],\n",
    "                                                      np.reshape(real_labels, (batch_size, 1)))\n",
    "            dis_loss_fake = stage2_dis.train_on_batch([hr_fake_images, compressed_embedding],\n",
    "                                                      np.reshape(fake_labels, (batch_size, 1)))\n",
    "            dis_loss_wrong = stage2_dis.train_on_batch([X_hr_train_batch[:(batch_size - 1)], compressed_embedding[1:]],\n",
    "                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\n",
    "            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong,  dis_loss_fake))\n",
    "            print(\"d_loss:{}\".format(d_loss))\n",
    "\n",
    "            \"\"\"\n",
    "            Train the adversarial model\n",
    "            \"\"\"\n",
    "            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],\n",
    "                                                                [K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n",
    "\n",
    "            print(\"g_loss:{}\".format(g_loss))\n",
    "\n",
    "            dis_losses.append(d_loss)\n",
    "            gen_losses.append(g_loss)\n",
    "\n",
    "        \"\"\"\n",
    "        Save losses to Tensorboard after each epoch\n",
    "        \"\"\"\n",
    "        write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n",
    "        write_log(tensorboard, 'generator_loss', np.mean(gen_losses), epoch)\n",
    "\n",
    "        # Generate and save images after every 2nd epoch\n",
    "        if epoch % 2 == 0:\n",
    "            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
    "            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
    "            embedding_batch = embeddings_test[0:batch_size]\n",
    "\n",
    "            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise2], verbose=3)\n",
    "            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\n",
    "\n",
    "            # Save images\n",
    "            for i, img in enumerate(hr_fake_images[:10]):\n",
    "                save_rgb_img(img, \"results2/gen_{}_{}.png\".format(epoch, i))\n",
    "\n",
    "    # Saving the models\n",
    "    stage2_gen.save_weights(\"stage2_gen.h5\")\n",
    "    stage2_dis.save_weights(\"stage2_dis.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hf_xM9WHJUXq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "stackgan_stage_2_implementation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
